{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"210728 colab_word2vec.ipynb","provenance":[],"authorship_tag":"ABX9TyMImoNinCWkcPv6+XOITPUl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nUINbj1hj6Om"},"source":["<참조 : https://www.tensorflow.org/tutorials/text/word2vec?hl=ko>"]},{"cell_type":"code","metadata":{"id":"WgmPMmNpj5Yw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfE1F6uSkCbp"},"source":["## Word2Vec"]},{"cell_type":"code","metadata":{"id":"GjVCSQ87kAm-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ASXU0d0kgfW"},"source":["### Skipgram / negative sampling\n","- bag-of-words 모델 : 주변 문맥이 주어지면 단어를 예측\n","- skip-gram 모델(n-gram 모델) : 단어가 주어지면 단어의 문맥을 예측  \n","  \n","- 스킵 그램 모델의 훈련 목표 : 대상 단어가 주어지면 문맥 단어를 예측할 확률을 최대화\n","\n","  - $\\cfrac{1}{T} \\sum_{t=1}^T \\, \\sum_{-c \\le j\\le c, \\,\\, j \\not = 0}  \\, \\, log \\, p(w_{t+j} | w_t )$  \n","    - c : 훈련 컨텍스트의 크기\n","\n","  - $p \\left(w_O | w_I \\right) = \\cfrac{exp \\left(v \\prime _{w_O} ^T v_{w_I} \\right)}{\\sum_{w=1} ^W exp \\left(v \\prime _w ^T v_{w_I} \\right)}$  \n","    - $v, v \\prime$ : 단어의 대상 및 컨텍스트 벡터 표현\n","    - $W$ : 어휘 크기"]},{"cell_type":"code","metadata":{"id":"EbHTD72MkzrG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ylaR1dKos70"},"source":["### 01. 설정"]},{"cell_type":"code","metadata":{"id":"5M6rVYvGouiq","executionInfo":{"status":"ok","timestamp":1627434300334,"user_tz":-540,"elapsed":1290,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["import io\n","import re\n","import string\n","import tensorflow as tf\n","import tqdm\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dot, Embedding, Flatten\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_bxIbhIpACA","executionInfo":{"status":"ok","timestamp":1627434300338,"user_tz":-540,"elapsed":27,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"31GJD3sQpKDs","executionInfo":{"status":"ok","timestamp":1627438398660,"user_tz":-540,"elapsed":305,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["SEED = 42\n","AUTOTUNE = tf.data.AUTOTUNE"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dc7fHoY-pOeh","executionInfo":{"status":"ok","timestamp":1627434325503,"user_tz":-540,"elapsed":315,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":[""],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8PK6z75pS97"},"source":["#### 01. 01. 예문 벡터화\n","- 예문 : The wide road shimmered in the hot sun."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13HildMOpRMv","executionInfo":{"status":"ok","timestamp":1627434415074,"user_tz":-540,"elapsed":321,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"1f7808c4-445e-40ea-c6e1-ec9a2923284a"},"source":["# 토큰화\n","\n","sentence = 'The wide road shimmered in the hot sum'\n","tokens = list(sentence.lower().split())\n","print(len(tokens))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Rb-3ztspm6z","executionInfo":{"status":"ok","timestamp":1627434587525,"user_tz":-540,"elapsed":306,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"69997643-e8e6-4526-b177-4019d6835bb1"},"source":["# 토큰에서 정수 인덱스로 매핑을 저장하는 어휘\n","\n","vocab, index = {}, 1    # start indexing from 1\n","vocab['<pad>'] = 0    # add a padding token\n","\n","for token in tokens:\n","    if token not in vocab:\n","        vocab[token] = index\n","        index += 1\n","\n","vocab_size = len(vocab)\n","print(vocab)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sum': 7}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjuBj7KLqGh2","executionInfo":{"status":"ok","timestamp":1627434626573,"user_tz":-540,"elapsed":309,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"518c8ef6-f7b4-490b-8944-b1014d388302"},"source":["inverse_vocab = {index:token for token, index in vocab.items()}\n","print(inverse_vocab)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sum'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8huQP_S1qasP","executionInfo":{"status":"ok","timestamp":1627434676044,"user_tz":-540,"elapsed":278,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"16ba9986-7599-45a1-9bc2-9fc9f00ad3f0"},"source":["# 문장을 벡터화\n","example_sequence = [vocab[word] for word in tokens]\n","print(example_sequence)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[1, 2, 3, 4, 5, 1, 6, 7]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9hEXfKJJqmyc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fykVgDTeq0tr"},"source":["#### 01. 02. 한 문장에서 스킵 그램 생성\n","- tf.keras.preprocessing.sequence 모듈 : 데이터 준비를 단순화하는 유용한 기능 제공\n","- tf.keras.preprocessing.sequence.skipgrams : [0, vocab_size] 범위의 토큰에서 주어진 window_size, example_sequence 에서 스킵 그램 쌍을 생성"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CmXy8dHProsb","executionInfo":{"status":"ok","timestamp":1627435229334,"user_tz":-540,"elapsed":328,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"1fef0a51-a822-411f-9786-9223420c6e0f"},"source":["window_size = 2\n","positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n","    example_sequence,\n","    vocabulary_size=vocab_size,\n","    window_size=window_size,\n","    negative_samples=0\n",")\n","print(len(positive_skip_grams))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["26\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPmKcvNzst2k","executionInfo":{"status":"ok","timestamp":1627435345430,"user_tz":-540,"elapsed":296,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"429b12e0-fc3d-4d7f-faf5-1b83d6526fe0"},"source":["for target, context in positive_skip_grams[:5]:\n","    print(f'({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(2, 1): (wide, the)\n","(3, 4): (road, shimmered)\n","(2, 3): (wide, road)\n","(1, 6): (the, hot)\n","(4, 1): (shimmered, the)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OWCv2XRhtKNZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3lc-k-WUtaXi"},"source":["#### 01. 03. 스킵 그램 1개에 대한 음성 샘플링\n","- skipgrams 함수 : 주어진 창 범위 위로 슬라이드 하여 모든 양의 스킴 그램 쌍을 반환\n","  - 학습을 위한 음성 샘플로 사용할 추가 스킵 그램 쌍을 생성하려면 어휘에서 임의의 단어를 샘플링해야 합니다  \n","    \n","- tf.random.log_uniform_candidate_sampler 함수 : 창에서 주어진 대상 단어에 대해 num_ns 개의 음수 샘플을 샘플링합니다"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyaC8fW4t4ng","executionInfo":{"status":"ok","timestamp":1627436016332,"user_tz":-540,"elapsed":304,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"fa2e2882-8fe1-4dfb-d605-603dd33fb32d"},"source":["# Get target and context words for one positive skip-gram\n","target_word, context_word = positive_skip_grams[0]\n","\n","# Set the number of negtive samples per positive context.\n","num_ns = 4\n","\n","context_class = tf.reshape(tf.constant(context_word, dtype='int64'), (1, 1))\n","\n","negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n","    true_classes=context_class,    # class that should be sampled as 'positive'\n","    num_true=1,    # each positive skip-gram has 1 positive context class\n","    num_sampled=num_ns,    # number of negative context words to sample\n","    unique=True,    # all the negative samples should be unique\n","    range_max=vocab_size,    # pick index of the samples from [0, vocab_size]\n","    seed=SEED,    # seed for reproducibility\n","    name='negative_sampling'    # name of this operation\n",")\n","print(negative_sampling_candidates)\n","print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"],"execution_count":14,"outputs":[{"output_type":"stream","text":["tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n","['wide', 'the', 'shimmered', 'road']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PoEbGfg3vLF6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kl_oP_tNv01V"},"source":["#### 01. 04. 교육 예제"]},{"cell_type":"code","metadata":{"id":"uQnlVMPOv8ho","executionInfo":{"status":"ok","timestamp":1627436259242,"user_tz":-540,"elapsed":287,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["# Add a dimension so you can use concatenation (on the next step).\n","negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n","\n","# Concat positive context word with negative sampled words.\n","context = tf.concat([context_class, negative_sampling_candidates], 0)\n","\n","# Label first context word as 1 (positive) followed by num_ns 0s (negative).\n","label = tf.constant([1] + [0]*num_ns, dtype='int64')\n","\n","# Reshape target to shape (1, ) and context and label to (num_ns+1, ).\n","target = tf.squeeze(target_word)\n","context = tf.squeeze(context)\n","label = tf.squeeze(label)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSQhcErrwpQ9","executionInfo":{"status":"ok","timestamp":1627436444914,"user_tz":-540,"elapsed":314,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"ef105191-18a6-4cf1-e31a-8b53b2b148bb"},"source":["print(f'target_index    : {target}')\n","print(f'target_word     : {inverse_vocab[target_word]}')\n","print(f'context_indices : {context}')\n","print(f'context_words   : {[inverse_vocab[c.numpy()] for c in context]}')\n","print(f'label           : {label}')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["target_index    : 2\n","target_word     : wide\n","context_indices : [1 2 1 4 3]\n","context_words   : ['the', 'wide', 'the', 'shimmered', 'road']\n","label           : [1 0 0 0 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2z5LGob1w5IA","executionInfo":{"status":"ok","timestamp":1627436503617,"user_tz":-540,"elapsed":310,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"be5a3396-358c-4e11-bb16-b43ff810cc4f"},"source":["print('target   : ', target)\n","print('context  : ', context)\n","print('label    : ', label)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["target   :  tf.Tensor(2, shape=(), dtype=int32)\n","context  :  tf.Tensor([1 2 1 4 3], shape=(5,), dtype=int64)\n","label    :  tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SUkapkCzxk3B"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N80ALskNx2Z4"},"source":["### 02. 모든 단계를 함수 하나로 컴파일"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYhfIF1Nx-Yj","executionInfo":{"status":"ok","timestamp":1627436782775,"user_tz":-540,"elapsed":301,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"7bd77eb3-d457-4343-c055-1e778eb965d2"},"source":["# 스킵 그램 샘플링 테이블\n","# sampling_table[i] : 데이터 세트에서 i번째로 가장 흔한 단어를 샘플링 할 확률을 나타냅니다.\n","#     이 함수는 샘플링을 위해 단어 주파수의 zipf 분포를 가정합니다\n","\n","sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n","print(sampling_table)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n"," 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GDEjMm9XyKwz","executionInfo":{"status":"ok","timestamp":1627438823276,"user_tz":-540,"elapsed":305,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["# 훈련 데이터 생성\n","\n","# Generates skip_gram pairs with negative sampling for a list of sequences\n","# (int-encoded sentences) based on window size, number of negative samples\n","# and vocabulary size.\n","def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n","    # Elements of each training example are appended to these lists.\n","    targets, contexts, labels = [], [], []\n","\n","    # Build the sampling table for vacab_size tokens.\n","    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n","\n","    # Iterte over all sequences (sentences) in dataset.\n","    for sequence in tqdm.tqdm(sequences):\n","\n","        # Generate positive skip-gram pairs for a swquence (sentence).\n","        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n","            sequence,\n","            vocabulary_size=vocab_size,\n","            sampling_table=sampling_table,\n","            window_size=window_size,\n","            negative_samples=0\n","        )\n","\n","        # Iterate over each positive skip-gram pair to produce training examples\n","        # with positive context word and negative samples.\n","        for target_word, context_word in positive_skip_grams:\n","            context_class = tf.expand_dims(\n","                tf.constant([context_word], dtype='int64'), \n","                1\n","            )\n","            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n","                true_classes=context_class,\n","                num_true=1,\n","                num_sampled=num_ns,\n","                unique=True,\n","                range_max=vocab_size,\n","                seed=SEED,\n","                name='negative_sampling'\n","            )\n","\n","            # Build context and label vectors (for one target word)\n","            negative_sampling_candidates = tf.expand_dims(\n","                negative_sampling_candidates, \n","                1\n","            )\n","\n","            context = tf.concat([context_class, negative_sampling_candidates], 0)\n","            label = tf.constant([1] + [0]*num_ns, dtype='int64')\n","\n","            # Append each element from the training example to global lists.\n","            targets.append(target_word)\n","            contexts.append(context)\n","            labels.append(label)\n","\n","    return targets, contexts, labels"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGGFLNb3133O"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7lyHpb71-4m"},"source":["### 03. Word2Vec에 대한 데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"2PuDu1Wd2nBU"},"source":["#### 03. 01. text corpus download"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mutgjgyf2CPy","executionInfo":{"status":"ok","timestamp":1627437751861,"user_tz":-540,"elapsed":327,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"4ea49363-03c3-423d-8075-d3437cd49619"},"source":["# 텍스트 코퍼스 다운로드\n","path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1122304/1115394 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5w6FUUs2VsO","executionInfo":{"status":"ok","timestamp":1627437803122,"user_tz":-540,"elapsed":299,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"c326420c-f63f-4c45-f2ce-a003dd214b36"},"source":["with open(path_to_file) as f:\n","    lines = f.read().splitlines()\n","for line in lines[:20]:\n","    print(line)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RmTwsnpg2iHT","executionInfo":{"status":"ok","timestamp":1627437885157,"user_tz":-540,"elapsed":272,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6UCMczR22Ir"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7YUMAWTP229d"},"source":["#### 03. 02. 말뭉치에서 문장 벡터화"]},{"cell_type":"code","metadata":{"id":"9yZt2giQ267P","executionInfo":{"status":"ok","timestamp":1627438216870,"user_tz":-540,"elapsed":282,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["# Now, create a custom standardization function to lowercase the text and remove punctuation.\n","def custom_standardization(input_data):\n","    lowercase = tf.strings.lower(input_data)\n","    return tf.strings.regex_replace(lowercase,\n","                                    '[%s]' % re.escape(string.punctuation), '')\n","    \n","\n","# Define the vocabulary size and number of words in a sequence.\n","vocab_size = 4096\n","sequence_length = 10\n","\n","# Use the text vectorization layer to normalize, split, and map strings to integers.\n","# Set output_sequence_length lengnth to pad all samples to same length.\n","vectorize_layer = TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=vocab_size,\n","    output_mode='int',\n","    output_sequence_length=sequence_length\n",")"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"WooaFXXm4FCj","executionInfo":{"status":"ok","timestamp":1627438266999,"user_tz":-540,"elapsed":1646,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["# 어휘 생성 : 텍스트 데이터 세트에서 adapt를 호출\n","vectorize_layer.adapt(text_ds.batch(1024))"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTh06Iz-4TIP","executionInfo":{"status":"ok","timestamp":1627438310098,"user_tz":-540,"elapsed":304,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"e4d016a7-0284-44ad-bc4c-17206747fb81"},"source":["# Save the created vocabulary for reference.\n","inverse_vocab = vectorize_layer.get_vocabulary()\n","print(inverse_vocab[:20])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hCWLeFQZ4d-v","executionInfo":{"status":"ok","timestamp":1627438410354,"user_tz":-540,"elapsed":333,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["# Vectorize the data in text_ds.\n","text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lt-cRKi4rxv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cy2wZU6H46b_"},"source":["#### 03. 03. 데이터 세트에서 시퀀스 가져오기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DADriVog4_lJ","executionInfo":{"status":"ok","timestamp":1627438498058,"user_tz":-540,"elapsed":2621,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"d963d7b8-f58c-45a1-8b93-5a7afe40e76a"},"source":["sequences = list(text_vector_ds.as_numpy_iterator())\n","print(len(sequences))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["32777\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6J9xGOS5LNF","executionInfo":{"status":"ok","timestamp":1627438556734,"user_tz":-540,"elapsed":415,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"db70b486-2428-4156-e941-ae831128fa3b"},"source":["for seq in sequences[:5]:\n","    print(f'{seq} => {[inverse_vocab[i] for i in seq]}')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n","[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n","[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n","[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n","[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F-QMgFxj5aKz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCKtL6KQ5dfq"},"source":["#### 03. 04. 시퀀스에서 훈련 예제"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEd1nGOl5jkH","executionInfo":{"status":"ok","timestamp":1627438864287,"user_tz":-540,"elapsed":34046,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"3e3d9716-ad63-44d1-f6b5-970511f62d63"},"source":["targets, contexts, labels = generate_training_data(\n","    sequences=sequences,\n","    window_size=2,\n","    num_ns=4,\n","    vocab_size=vocab_size,\n","    seed=SEED\n",")\n","print(len(targets), len(contexts), len(labels))"],"execution_count":39,"outputs":[{"output_type":"stream","text":["100%|██████████| 32777/32777 [00:33<00:00, 971.15it/s] "],"name":"stderr"},{"output_type":"stream","text":["65016 65016 65016\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GO8dRYxt6g_T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xiqsmVpl6jtQ"},"source":["#### 03. 04. 성능을 위한 데이터 세트 구성"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxSegRrI54I1","executionInfo":{"status":"ok","timestamp":1627438981159,"user_tz":-540,"elapsed":3023,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"be1145d0-5d68-4cda-fb8b-b11195653a0e"},"source":["BATCH_SIZE =1024\n","BUFFER_SIZE = 10000\n","dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print(dataset)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["<BatchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sThuoKXL67rj","executionInfo":{"status":"ok","timestamp":1627439009038,"user_tz":-540,"elapsed":27,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"1fdd7215-cf3e-43b5-dace-1c7088ed5061"},"source":["dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","print(dataset)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["<PrefetchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lEqCdE1g7IWi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9qdJS2MW7K0w"},"source":["### 04. 모델 및 훈련\n","- 서브 클래싱된 Word2Vec 모델 : Keras Subclassing API 사용\n","  - target_embedding : 대상 단어로 표시될 때 단어의 임베딩을 조회하는 tf.keras.layers.Embedding 레이어\n","    - 매개변수 : (vocab_size * embedding_dim)\n","  - context_embedding : 문맥 단어로 나타날 때 단어의 임베딩을 조회하는 레이어\n","    - 매개변수 : target_embedding의 매개변수와 개수 동일합니다\n","  - dots : 학습 쌍에서 대상 및 컨텍스트 임베딩의 내적을 계산\n","  - flatten : dots 레이어의 결과를 tf.keras.layers.Flatten으로 병합하는 레이어"]},{"cell_type":"code","metadata":{"id":"VG3RmByo8H0z","executionInfo":{"status":"ok","timestamp":1627439906874,"user_tz":-540,"elapsed":405,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["class Word2Vec(Model):\n","    def __init__(self, vocab_size, embedding_dim):\n","        super(Word2Vec, self).__init__()\n","        self.target_embedding = Embedding(vocab_size,\n","                                          embedding_dim,\n","                                          input_length=1,\n","                                          name='w2v_embedding')\n","        self.context_embedding = Embedding(vocab_size,\n","                                           embedding_dim,\n","                                           input_length=num_ns+1)\n","        self.dots = Dot(axes=(3, 2))\n","        self.flatten = Flatten()\n","\n","    def call(self, pair):\n","        target, context = pair\n","        word_emb = self.target_embedding(target)\n","        context_emb = self.context_embedding(context)\n","        dots = self.dots([context_emb, word_emb])\n","        return self.flatten(dots)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"kk6_3DRl9I9a","executionInfo":{"status":"ok","timestamp":1627439908480,"user_tz":-540,"elapsed":8,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":[""],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cOcN3Ach9Wxb"},"source":["- 손실함수 정의 및 모델 컴파일"]},{"cell_type":"code","metadata":{"id":"hqWY_W819aEc","executionInfo":{"status":"ok","timestamp":1627439908815,"user_tz":-540,"elapsed":6,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["def custom_loss(x_logit, y_true):\n","    return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"AepaTcZu9l-7","executionInfo":{"status":"ok","timestamp":1627439909215,"user_tz":-540,"elapsed":12,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["embedding_dim = 128\n","word2vec = Word2Vec(vocab_size, embedding_dim)\n","word2vec.compile(optimizer='adam',\n","                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","                 metrics=['accuracy'])"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_dKsZzO98ZS","executionInfo":{"status":"ok","timestamp":1627439910770,"user_tz":-540,"elapsed":511,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAWa7Nkv-DIe","executionInfo":{"status":"ok","timestamp":1627439934053,"user_tz":-540,"elapsed":22907,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"88319036-30c2-470b-9b29-4f387403bc16"},"source":["word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","63/63 [==============================] - 4s 20ms/step - loss: 1.6082 - accuracy: 0.2332\n","Epoch 2/20\n","63/63 [==============================] - 1s 11ms/step - loss: 1.5884 - accuracy: 0.5522\n","Epoch 3/20\n","63/63 [==============================] - 1s 12ms/step - loss: 1.5396 - accuracy: 0.5928\n","Epoch 4/20\n","63/63 [==============================] - 1s 12ms/step - loss: 1.4566 - accuracy: 0.5648\n","Epoch 5/20\n","63/63 [==============================] - 1s 12ms/step - loss: 1.3597 - accuracy: 0.5715\n","Epoch 6/20\n","63/63 [==============================] - 1s 12ms/step - loss: 1.2650 - accuracy: 0.5993\n","Epoch 7/20\n","63/63 [==============================] - 1s 12ms/step - loss: 1.1766 - accuracy: 0.6340\n","Epoch 8/20\n","63/63 [==============================] - 1s 12ms/step - loss: 1.0942 - accuracy: 0.6688\n","Epoch 9/20\n","63/63 [==============================] - 1s 12ms/step - loss: 1.0172 - accuracy: 0.7021\n","Epoch 10/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.9454 - accuracy: 0.7316\n","Epoch 11/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.8784 - accuracy: 0.7582\n","Epoch 12/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.8164 - accuracy: 0.7814\n","Epoch 13/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.7591 - accuracy: 0.8019\n","Epoch 14/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.7065 - accuracy: 0.8194\n","Epoch 15/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.6582 - accuracy: 0.8348\n","Epoch 16/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.6141 - accuracy: 0.8489\n","Epoch 17/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.5739 - accuracy: 0.8610\n","Epoch 18/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.5373 - accuracy: 0.8720\n","Epoch 19/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.5039 - accuracy: 0.8821\n","Epoch 20/20\n","63/63 [==============================] - 1s 12ms/step - loss: 0.4736 - accuracy: 0.8913\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb83510a790>"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"sEdmBphK-Ihz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ItwEImL3AdM5"},"source":["### 05. 조회 / 분석"]},{"cell_type":"markdown","metadata":{"id":"BuXbFrwdBJA3"},"source":["- get_layer() / get_weights() : 모델에서 가중치를 얻습니다\n","- get_vocabulary() : 한 줄에 하나의 토큰으로 메타 데이터 파일을 빌드하기 위한 어휘를 제공합니다"]},{"cell_type":"code","metadata":{"id":"BB3cYaaBAjpH","executionInfo":{"status":"ok","timestamp":1627440683770,"user_tz":-540,"elapsed":418,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n","vocab = vectorize_layer.get_vocabulary()"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXLAqRGVBhdN","executionInfo":{"status":"ok","timestamp":1627440860184,"user_tz":-540,"elapsed":422,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}}},"source":["out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n","out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n","\n","for index, word in enumerate(vocab):\n","    if index == 0:\n","        continue    # skip 0, it's padding.\n","    vec = weights[index]\n","    out_v.write('\\t'.join([str(x) for x in vec]) + '\\n')\n","    out_m.write(word + '\\n')\n","\n","out_v.close()\n","out_m.close()"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"xns7y6tFCMiq","executionInfo":{"status":"ok","timestamp":1627440918763,"user_tz":-540,"elapsed":439,"user":{"displayName":"Soph Jang","photoUrl":"","userId":"14835909760619044951"}},"outputId":"31309efd-75df-4137-831d-0ab7f40c2ff8"},"source":["try:\n","    from google.colab import files\n","    files.download('vectors.tsv')\n","    files.download('metadata.tsv')\n","except Exception:\n","    pass"],"execution_count":60,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_67ef9957-65de-4d4c-aab7-42b84adb052d\", \"vectors.tsv\", 6114530)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_c5f0c8a5-a652-4aa0-acd3-0690a7aa4dfe\", \"metadata.tsv\", 28737)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"w6W3ZeG8Cayf"},"source":[""],"execution_count":null,"outputs":[]}]}