{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f83192",
   "metadata": {},
   "source": [
    "<참조 : https://www.tensorflow.org/tutorials/distribute/keras?hl=ko>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace12d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "247aeea0",
   "metadata": {},
   "source": [
    "## 케라스를 사용한 분산훈련\n",
    "- tf.distribute.Strategy : 훈련을 여러 처리 장치들로 분산시키는 것을 추상화한 것입니다\n",
    "  - 기존 모델이나 훈련 코드를 조금 바꾸어 분산 훈련을 할 수 있게 하는 것이 분산 전략 API의 목표\n",
    "- tf.distribute.MirroredStrategy 사용\n",
    "  - 동기화된 훈련 방식을 활용하여 한 장비에 여러 개의 GPU로 그래프 내 복제를 수행합니다\n",
    "  - 모델의 모든 변수를 각 프로세서에 복사합니다\n",
    "  - 각 프로세서의 그래디언트(gradient)를 올 리듀스(all-reduce)를 사용하여 모읍니다\n",
    "  - 계산한 값을 각 프로세서의 모델 복사본에 적용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523332dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe07f93",
   "metadata": {},
   "source": [
    "### 01. 필요한 패키지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095d6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로와 텐서플로 데이터셋 패키지 가져오기\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767cf1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82e38aa1",
   "metadata": {},
   "source": [
    "### 02. Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046105a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\jjanh_000\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n",
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\jjanh_000\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8b089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1425aa37",
   "metadata": {},
   "source": [
    "### 03. 분산 전략 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc598568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9495d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장치 수: 1\n"
     ]
    }
   ],
   "source": [
    "print('장치 수: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07918136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50a82166",
   "metadata": {},
   "source": [
    "### 04. 입력 파이프라인 구성하기\n",
    "- 다중 GPU로 모델을 훈련할 때는 배치 크기를 늘려야 컴퓨팅 자원을 효과적으로 사용할 수 있습니다\n",
    "- GPU 메모리에 맞추어 가능한 가장 큰 배치 크기를 사용합니다\n",
    "  - 이에 맞게 학습률도 조정해야 합니다\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f8ee2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 내 샘플 수는 info.splits.total_num_examples로도 얻을 수 있습니다\n",
    "\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 62\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8225920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 픽셀 값은 0~255 : 0~1 범위로 정규화\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032f8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342ab1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dba6d1a1",
   "metadata": {},
   "source": [
    "### 05. 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f69848",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6346d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab90d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1cc3df",
   "metadata": {},
   "source": [
    "### 06. 콜백 정의하기\n",
    "- 텐서보드(TensorBoard) : 텐서보드용 로그를 남겨서, 텐서보드에서 그래프를 그릴 수 있게 합니다\n",
    "- 모델 체크포인트(Checkpoint) : 매 에포크(epoch)가 끝난 후 모델을 저장합니다\n",
    "- 학습률 스케줄러 : 매 에포크 혹은 배치가 끝난 후 학습률을 바꿀 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7094375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트를 저장할 체크포인트 디렉토리를 지정합니다\n",
    "checkpoint_dir = './dK_training_checkpoints'\n",
    "\n",
    "# 체크포인트 파일의 이름\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8456c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률을 점점 줄이기 위한 함수\n",
    "# 필요한 함수를 직접 정의하여 사용할 수 있습ㄴ다\n",
    "\n",
    "def decay(epoch):\n",
    "    if epoch < 3:\n",
    "        return 1e-3\n",
    "    if epoch >3 and epoch < 7:\n",
    "        return 1e-4\n",
    "    else:\n",
    "        return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4832a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크가 끝날 때마다 학습률을 출력하는 콜백\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\n에포크 {}의 학습률은 {}입니다.'.format(epoch+1, model.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed55cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./dK_logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                      save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0ecd9ee",
   "metadata": {},
   "source": [
    "### 07. 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29add030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "  6/968 [..............................] - ETA: 6:53 - loss: 2.0570 - accuracy: 0.4113WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0864s vs `on_train_batch_end` time: 0.2818s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0864s vs `on_train_batch_end` time: 0.2818s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968/968 [==============================] - 103s 99ms/step - loss: 0.2078 - accuracy: 0.9394s - loss: 0.2108 - ac\n",
      "\n",
      "에포크 1의 학습률은 0.0010000000474974513입니다.\n",
      "Epoch 2/12\n",
      "968/968 [==============================] - 65s 66ms/step - loss: 0.0689 - accuracy: 0.9795\n",
      "\n",
      "에포크 2의 학습률은 0.0010000000474974513입니다.\n",
      "Epoch 3/12\n",
      "968/968 [==============================] - 78s 80ms/step - loss: 0.0471 - accuracy: 0.9861\n",
      "\n",
      "에포크 3의 학습률은 0.0010000000474974513입니다.\n",
      "Epoch 4/12\n",
      "968/968 [==============================] - 82s 84ms/step - loss: 0.0301 - accuracy: 0.9917\n",
      "\n",
      "에포크 4의 학습률은 9.999999747378752e-06입니다.\n",
      "Epoch 5/12\n",
      "968/968 [==============================] - 77s 78ms/step - loss: 0.0254 - accuracy: 0.9931\n",
      "\n",
      "에포크 5의 학습률은 9.999999747378752e-05입니다.\n",
      "Epoch 6/12\n",
      "968/968 [==============================] - 73s 74ms/step - loss: 0.0227 - accuracy: 0.9943\n",
      "\n",
      "에포크 6의 학습률은 9.999999747378752e-05입니다.\n",
      "Epoch 7/12\n",
      "968/968 [==============================] - 74s 75ms/step - loss: 0.0208 - accuracy: 0.9947\n",
      "\n",
      "에포크 7의 학습률은 9.999999747378752e-05입니다.\n",
      "Epoch 8/12\n",
      "968/968 [==============================] - 74s 75ms/step - loss: 0.0183 - accuracy: 0.9956\n",
      "\n",
      "에포크 8의 학습률은 9.999999747378752e-06입니다.\n",
      "Epoch 9/12\n",
      "968/968 [==============================] - 76s 78ms/step - loss: 0.0179 - accuracy: 0.9958\n",
      "\n",
      "에포크 9의 학습률은 9.999999747378752e-06입니다.\n",
      "Epoch 10/12\n",
      "968/968 [==============================] - 92s 94ms/step - loss: 0.0177 - accuracy: 0.9958\n",
      "\n",
      "에포크 10의 학습률은 9.999999747378752e-06입니다.\n",
      "Epoch 11/12\n",
      "968/968 [==============================] - 80s 81ms/step - loss: 0.0175 - accuracy: 0.9959\n",
      "\n",
      "에포크 11의 학습률은 9.999999747378752e-06입니다.\n",
      "Epoch 12/12\n",
      "968/968 [==============================] - 83s 85ms/step - loss: 0.0173 - accuracy: 0.9960\n",
      "\n",
      "에포크 12의 학습률은 9.999999747378752e-06입니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1012abc1f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85026578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d576c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "# 체크포인트 디렉토리 확인하기\n",
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e345957",
   "metadata": {},
   "source": [
    "#### goole 검색 : python directory file list -> https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "```python\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "```\n",
    "- ---------------------------------------------------------------------\n",
    "```python\n",
    "from os import walk\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "```\n",
    "- ---------------------------------------------------------------------\n",
    "```python\n",
    "from os import walk\n",
    "\n",
    "filenames = next(walk(mypath), (None, None, []))[2]  # [] if no file\n",
    "```\n",
    "- ---------------------------------------------------------------------\n",
    "```python\n",
    "for (dirpath, dirnames, filenames) in os.walk(mypath):\n",
    "    checksum_files.extend(os.path.join(dirpath, filename) for filename in filenames) \n",
    "    break\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e491756",
   "metadata": {},
   "source": [
    "#### https://careerkarma.com/blog/python-list-files-in-directory/  \n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "path = '/home/data_analysis/netflix'\n",
    "\n",
    "files = os.listdir(path)\n",
    "\n",
    "for f in files:\n",
    "\tprint(f)\n",
    "```\n",
    "- ---------------------------------------------------------------------\n",
    "```python\n",
    "import os\n",
    "\n",
    "path = '/home/data_analysis/netflix'\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=False):\n",
    "\tfor name in files:\n",
    "\t\tprint(os.path.join(root, name))\n",
    "\tfor name in directories:\n",
    "\t\tprint(os.path.join(root, name))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3cd314",
   "metadata": {},
   "source": [
    "#### 다른 표현식\n",
    "- (_, _, filenames) = walk(mypath).next()\n",
    "- f.extend(filenames) : f += filenames\n",
    "  - not : f = f + filenames\n",
    "- _, _, filenames = next(walk(mypath), (None, None, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198f9e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "ckpt_1.data-00000-of-00001\n",
      "ckpt_1.index\n",
      "ckpt_10.data-00000-of-00001\n",
      "ckpt_10.index\n",
      "ckpt_11.data-00000-of-00001\n",
      "ckpt_11.index\n",
      "ckpt_12.data-00000-of-00001\n",
      "ckpt_12.index\n",
      "ckpt_2.data-00000-of-00001\n",
      "ckpt_2.index\n",
      "ckpt_3.data-00000-of-00001\n",
      "ckpt_3.index\n",
      "ckpt_4.data-00000-of-00001\n",
      "ckpt_4.index\n",
      "ckpt_5.data-00000-of-00001\n",
      "ckpt_5.index\n",
      "ckpt_6.data-00000-of-00001\n",
      "ckpt_6.index\n",
      "ckpt_7.data-00000-of-00001\n",
      "ckpt_7.index\n",
      "ckpt_8.data-00000-of-00001\n",
      "ckpt_8.index\n",
      "ckpt_9.data-00000-of-00001\n",
      "ckpt_9.index\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(checkpoint_dir)\n",
    "\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f54a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c940c3c1",
   "metadata": {},
   "source": [
    "- 모델의 성능 확인 : 가장 최근 체크포인트를 불러온 후 테스트 데이터에 대하여 evaluate를 호출합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "250ad3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 8s 31ms/step - loss: 0.0395 - accuracy: 0.9871\n",
      "평가 손실: 0.03950142487883568, 평가 정확도: 0.9871000051498413\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "\n",
    "print('평가 손실: {}, 평가 정확도: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10aca1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "690a7328",
   "metadata": {},
   "source": [
    "### 08. SavedModel로 내보내기\n",
    "- 플랫폼과 무관한 SavedModel 형식으로 그래프와 변수들을 내보냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05957134",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'saved_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d2bac7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.experimental' has no attribute 'export_saved_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7f22af6799f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.experimental' has no attribute 'export_saved_model'"
     ]
    }
   ],
   "source": [
    "tf.keras.experimental.export_saved_model(model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde1ff2",
   "metadata": {},
   "source": [
    "#### 오류 발생하여 검색 : https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/experimental/export_saved_model\n",
    "\n",
    "- 튜토리얼 코드 수정하여 성공  \n",
    "  \n",
    "  \n",
    "- 모델을 저장하고 저장한 모델을 불러와서 사용\n",
    "- 다시 훈련시키지 않아도 됩니다  \n",
    "  \n",
    "    \n",
    "- 블로그 링크 : https://hwiyong.tistory.com/116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "253b1a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjanh_000\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model_experimental.py:117: UserWarning: `tf.keras.experimental.export_saved_model` is deprecatedand will be removed in a future version. Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
      "  warnings.warn('`tf.keras.experimental.export_saved_model` is deprecated'\n",
      "C:\\Users\\jjanh_000\\anaconda3\\lib\\site-packages\\keras\\backend.py:459: UserWarning: `tf.keras.backend.learning_phase_scope` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.learning_phase_scope` is deprecated and '\n",
      "C:\\Users\\jjanh_000\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2427: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjanh_000\\anaconda3\\lib\\site-packages\\keras\\saving\\utils_v1\\signature_def_utils.py:63: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jjanh_000\\anaconda3\\lib\\site-packages\\keras\\saving\\utils_v1\\signature_def_utils.py:63: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: saved_model/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: saved_model/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.keras.experimental.export_saved_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404851a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e97f265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjanh_000\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model_experimental.py:400: UserWarning: `tf.keras.experimental.load_from_saved_model` is deprecatedand will be removed in a future version. Please switch to `tf.keras.models.load_model`.\n",
      "  warnings.warn('`tf.keras.experimental.load_from_saved_model` is deprecated'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 5s 28ms/step - loss: 0.0395 - accuracy: 0.9871\n",
      "평가 손실: 0.03950142487883568, 평가 정확도: 0.9871000051498413\n"
     ]
    }
   ],
   "source": [
    "unreplicated_model = tf.compat.v1.keras.experimental.load_from_saved_model(path)\n",
    "\n",
    "unreplicated_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
    "\n",
    "print('평가 손실: {}, 평가 정확도: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7597d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
