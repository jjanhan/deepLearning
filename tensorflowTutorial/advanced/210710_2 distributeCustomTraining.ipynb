{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7cb0658",
   "metadata": {},
   "source": [
    "<참조 : https://www.tensorflow.org/tutorials/distribute/custom_training?hl=ko>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afd7bf4c",
   "metadata": {},
   "source": [
    "## custon training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6cd482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0-dev20210708\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24453d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c63c9e0",
   "metadata": {},
   "source": [
    "### 01. Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1190425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "40960/29515 [=========================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 11s 0us/step\n",
      "26435584/26421880 [==============================] - 11s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n",
      "4431872/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617558bc",
   "metadata": {},
   "source": [
    "- 배열에 한 차원 추가 : shape=(28, 28, 1)\n",
    "  - 모델에서 첫 번째 층이 합성곱 층 : 4D 입력을 요구\n",
    "  - (batch_size, height, width, channels)\n",
    "  - batch_size 차원은 나중에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaffff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images[..., None]\n",
    "test_images = test_images[..., None]\n",
    "\n",
    "train_images = train_images / np.float32(255)\n",
    "test_images = test_images / np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83a053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1596cde4",
   "metadata": {},
   "source": [
    "### 02. 분산 전략 수립\n",
    "- tf.distribute.MirroredStrategy 동작\n",
    "  - 모든 변수와 모델 그래프는 장치(replicas)에 복제됩니다\n",
    "  - 입력은 장치에 고르게 분배되어 들어갑니다\n",
    "  - 각 장치는 주어지는 입력에 대해서 손실(loss)과 그래디언트를 계산합니다\n",
    "  - 그래디언트들을 전부 더함으로써 모든 장치들 간에 그래디언트들이 동기화됩니다\n",
    "  - 동기화된 후에 동일한 업데이트가 각 장치에 있는 변수의 복사본에 동일하게 적용됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9213e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5712c8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장치 수: 1\n"
     ]
    }
   ],
   "source": [
    "print('장치 수: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3594b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6ca6605",
   "metadata": {},
   "source": [
    "### 03. 입력 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75804591",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_images)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA *strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f63625",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, \n",
    "                    train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, \n",
    "                    test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "    test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afa26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfb8ea6",
   "metadata": {},
   "source": [
    "### 04. 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b695765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be45bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './cT_training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c5934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a6dd2f9",
   "metadata": {},
   "source": [
    "### 05. 손실함수  \n",
    "  \n",
    "  - tf.distribute.Strategy 손실 계산 방법\n",
    "    - GPU 4개가 있고 입력 배치 크기가 64\n",
    "      - 입력 배치 하나가 GPU 4개에 분배됩니다\n",
    "      - 각 장치는 크기가 16(64 / 4 = 16)인 입력을 받습니다\n",
    "    - 각 장치에 있는 모델은 해당 입력에 대해 정방향 계산(forward pass)을 수행하고 손실 계산\n",
    "      - 손실은 16이 아니라 64로 나누어야 합니다  \n",
    "          \n",
    "    - 그래디언트들이 각 장치에서 계산된 다음, 모든 장치를 동기화하기 위해 이 그래디언트 값들을 전부 더하기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85888b7",
   "metadata": {},
   "source": [
    "##### 텐서플로우\n",
    "- custom training loops 작성\n",
    "  - 샘플당 손실을 더하고 GLOBAL_BATCH_SIZE로 나누어야 합니다\n",
    "  - scale_loss = tf.reduce_sum(loss) * (1./GLOBAL_BATCH_SIZE) \n",
    "  - 또는 tf.nn.compute_average_loss 함수 사용\n",
    "    - 샘플당 손실과 선택적으로 샘플 가중치, GLOBAL_BATCH_SIZE를 매개변수 값으로 받고 스케일이 조정된 손실을 반환  \n",
    "      \n",
    "  - 규제 손실을 사용하는 메델 : 장치 개수로 손실 값을 스케일 조정해야 합니다\n",
    "    - tf.nn.scale_regularization_loss 함수 사용하여 처리할 수 있습니다  \n",
    "      \n",
    "  - tf.reduct_main 사용은 추천하지 않습니다. 실제 장치당 배치 크기는 각 단계(step)마다 다를 수 있기 때문  \n",
    "    \n",
    "  - 축소(reduction)와 스케일 조정은 케라스의 model.compile과 model.fit에서 자동으로 수행됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eccb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # reduction을 'None'으로 설정합니다.\n",
    "    # 축소는 나중에 하고, GLOBAL_BATCH_SIZE로 나눌 수 있습니다\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    # loss_fn=tf.keras.losses.sparse_categorical_crossentropy를 사용해도 됩니다\n",
    "    \n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        \n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f256c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7d516f",
   "metadata": {},
   "source": [
    "### 06. 손실과 정확도를 기록\n",
    "  - 지표(metrics) : 테스트 손실과 훈련 정확도, 테스트 정확도를 기록\n",
    "  - .result() 사용 : 누적된 통계값들을 볼 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211fab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    \n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe99b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "321b1f6b",
   "metadata": {},
   "source": [
    "### 07. 훈련 루프\n",
    "- 모델과 옵티마이저는 'strategy.scope'에서 만들어져야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c91717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac265d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def train_step(inputs):\n",
    "        images, labels = inputs\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images, training=True)\n",
    "            loss = compute_loss(labels, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        train_accuracy.update_state(labels, predictions)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(inputs):\n",
    "        images, labels = inputs\n",
    "        \n",
    "        predictions = model(images, training=False)\n",
    "        t_loss = loss_object(labels, predictions)\n",
    "        \n",
    "        test_loss.update_state(t_loss)\n",
    "        test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af0d6421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1, 손실: 0.5145577788352966, 정확도: 81.40833282470703, 테스트 손실: 0.38852205872535706, 테스트 정확도:86.18000030517578\n",
      "에포크 2, 손실: 0.341645210981369, 정확도: 87.71333312988281, 테스트 손실: 0.33769115805625916, 테스트 정확도:87.73999786376953\n",
      "에포크 3, 손실: 0.29546600580215454, 정확도: 89.3316650390625, 테스트 손실: 0.31100043654441833, 테스트 정확도:88.73999786376953\n",
      "에포크 4, 손실: 0.2626648247241974, 정확도: 90.37000274658203, 테스트 손실: 0.2878546118736267, 테스트 정확도:89.58000183105469\n",
      "에포크 5, 손실: 0.23875999450683594, 정확도: 91.24333190917969, 테스트 손실: 0.27885299921035767, 테스트 정확도:89.75\n",
      "에포크 6, 손실: 0.21810439229011536, 정확도: 92.02166748046875, 테스트 손실: 0.27133476734161377, 테스트 정확도:90.02999877929688\n",
      "에포크 7, 손실: 0.2026626169681549, 정확도: 92.39166259765625, 테스트 손실: 0.2953889071941376, 테스트 정확도:89.60000610351562\n",
      "에포크 8, 손실: 0.18445955216884613, 정확도: 93.15666198730469, 테스트 손실: 0.2716430127620697, 테스트 정확도:90.29000091552734\n",
      "에포크 9, 손실: 0.16890506446361542, 정확도: 93.7683334350586, 테스트 손실: 0.25887611508369446, 테스트 정확도:90.94999694824219\n",
      "에포크 10, 손실: 0.1552819311618805, 정확도: 94.211669921875, 테스트 손실: 0.2662814259529114, 테스트 정확도:90.45999908447266\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # 'run'은 주어진 계산을 복사하고, 분산된 입력으로 계산을 수행합니다.\n",
    "    \n",
    "    @tf.function\n",
    "    def distributed_train_step(dataset_inputs):\n",
    "        per_replica_losses = strategy.run(train_step,\n",
    "                                         args=(dataset_inputs,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM,\n",
    "                              per_replica_losses, axis=None)\n",
    "    \n",
    "    @tf.function\n",
    "    def distributed_test_step(dataset_inputs):\n",
    "        return strategy.run(test_step, args=(dataset_inputs,))\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # train loop\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for x in train_dist_dataset:\n",
    "            total_loss += distributed_train_step(x)\n",
    "            num_batches += 1\n",
    "        train_loss = total_loss / num_batches\n",
    "        \n",
    "        # test loop\n",
    "        for x in test_dist_dataset:\n",
    "            distributed_test_step(x)\n",
    "            \n",
    "        if epoch % 2 == 0:\n",
    "            checkpoint.save(checkpoint_prefix)\n",
    "            \n",
    "        template = ('에포크 {}, 손실: {}, 정확도: {}, 테스트 손실: {}, '\n",
    "                   '테스트 정확도:{}')\n",
    "        \n",
    "        print(template.format(epoch+1, \n",
    "                             train_loss,\n",
    "                             train_accuracy.result()*100,\n",
    "                             test_loss.result(),\n",
    "                             test_accuracy.result()*100))\n",
    "        \n",
    "        test_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5de50b",
   "metadata": {},
   "source": [
    "- 이 예제는 train_dist_dataset과 test_dist_dataset을 for x in ... 구조를 통해서 반복합니다\n",
    "- 스케일이 조정된 손실은 distributed_train_step의 반환값입니다. tf.distribute.Strategy.reduce 호출을 사용해서 장치들 간의 스케일이 조정된 손실 값을 전부 합칩니다. 그리고 나서 tf.distribute.Strategy.reduce 반환 값을 더하는 식으로 배치 간의 손실을 모읍니다\n",
    "- tf.keras.Metrics는 tf.distribute.Strategy.run에 의해서 실행되는 train_step과 test_step 함수 안에서 업데이트 되어야 합니다\n",
    "- tf.distribute.Strategy.run는 그 전략안에 포함된 각 지역 복제 모델로부터 결과값을 반환해 줍니다. 그리고 이 결과를 사용하는 몇 가지 방법들이 있습니다. tf.distribute.Strategy.reduce를 이용하여 값들을 합칠 수 있습니다. tf.distribute.Strategy.experimental_local_results를 사용해서 결과값(지역 복제 모델 당 하나의 결과값)에 들어있는 값들의 리스트를 얻을 수도 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d3260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f53015fb",
   "metadata": {},
   "source": [
    "### 08. 최신 체크포인트를 불러와서 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5b09169",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='eval_accuracy')\n",
    "\n",
    "new_model = create_model()\n",
    "new_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d1b0331",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(images, labels):\n",
    "    predictions = new_model(images, training=False)\n",
    "    eval_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac60b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전략을 사용하지 않고, 저장된 모델을 복원한 후의 정확도: 90.94999694824219\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    eval_step(images, labels)\n",
    "    \n",
    "print('전략을 사용하지 않고, 저장된 모델을 복원한 후의 정확도: {}'.format(\n",
    "    eval_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b628e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09d7a27c",
   "metadata": {},
   "source": [
    "### 09. 데이터셋에 대해 반복작업을 하는 다른 방법들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460fe95",
   "metadata": {},
   "source": [
    "#### 09. 01. 반복자(iterator) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06e4378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 10, 손실: 0.14657068252563477, 정확도: 94.375\n",
      "에포크 10, 손실: 0.15810582041740417, 정확도: 94.6875\n",
      "에포크 10, 손실: 0.14461565017700195, 정확도: 95.46875\n",
      "에포크 10, 손실: 0.16386650502681732, 정확도: 94.53125\n",
      "에포크 10, 손실: 0.13576357066631317, 정확도: 94.21875\n",
      "에포크 10, 손실: 0.10729018598794937, 정확도: 96.09375\n",
      "에포크 10, 손실: 0.13755884766578674, 정확도: 95.3125\n",
      "에포크 10, 손실: 0.15774953365325928, 정확도: 93.59375\n",
      "에포크 10, 손실: 0.16980639100074768, 정확도: 92.96875\n",
      "에포크 10, 손실: 0.14132282137870789, 정확도: 94.6875\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    for _ in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        train_iter = iter(train_dist_dataset)\n",
    "        \n",
    "        for _ in range(10):\n",
    "            total_loss += distributed_train_step(next(train_iter))\n",
    "            num_batches += 1\n",
    "            \n",
    "        average_train_loss = total_loss / num_batches\n",
    "        \n",
    "        template = ('에포크 {}, 손실: {}, 정확도: {}')\n",
    "        print(template.format(epoch+1,\n",
    "                             average_train_loss,\n",
    "                             train_accuracy.result()*100))\n",
    "        train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7cd9d",
   "metadata": {},
   "source": [
    "#### 09. 02. tf.function 내부에서 반복하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b680a2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjanh_000\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:374: UserWarning: To make it possible to preserve tf.data options across serialization boundaries, their implementation has moved to be part of the TensorFlow graph. As a consequence, the options value is in general no longer known at graph construction time. Invoking this method in graph mode retains the legacy behavior of the original implementation, but note that the returned value might not reflect the actual value of the options.\n",
      "  warnings.warn(\"To make it possible to preserve tf.data options across \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1434594839811325, Accuracy: 94.71833038330078\n",
      "Epoch 2, Loss: 0.13020296394824982, Accuracy: 95.16666412353516\n",
      "Epoch 3, Loss: 0.120378278195858, Accuracy: 95.47332763671875\n",
      "Epoch 4, Loss: 0.1110435351729393, Accuracy: 95.82333374023438\n",
      "Epoch 5, Loss: 0.10154811292886734, Accuracy: 96.24166870117188\n",
      "Epoch 6, Loss: 0.09127387404441833, Accuracy: 96.6483383178711\n",
      "Epoch 7, Loss: 0.08671723306179047, Accuracy: 96.77833557128906\n",
      "Epoch 8, Loss: 0.07656186819076538, Accuracy: 97.19332885742188\n",
      "Epoch 9, Loss: 0.07146268337965012, Accuracy: 97.34833526611328\n",
      "Epoch 10, Loss: 0.06595834344625473, Accuracy: 97.54666900634766\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    @tf.function\n",
    "    def distributed_train_epoch(dataset):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for x in dataset:\n",
    "            per_replica_losses = strategy.run(train_step,\n",
    "                                             args=(x,))\n",
    "            total_loss += strategy.reduce(\n",
    "                tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "            num_batches += 1\n",
    "        return total_loss / tf.cast(num_batches, dtype=tf.float32)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = distributed_train_epoch(train_dist_dataset)\n",
    "        \n",
    "        template = ('Epoch {}, Loss: {}, Accuracy: {}')\n",
    "        print(template.format(epoch+1, train_loss,\n",
    "                             train_accuracy.result()*100))\n",
    "        \n",
    "        train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c5bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1d5d0bf",
   "metadata": {},
   "source": [
    "### 10. 장치 간의 훈련 손실 기록하기\n",
    "- 일반적인 규칙으로, tf.keras.Metrics를 사용하여 샘플당 손실 값을 기록하고 장치 내부에서 값이 합쳐지는 것을 피해야 합니다\n",
    "- tf.metrics.Meas : 손실의 스케일을 조정하는 계산이 수행되기 때문에 추천하지 않습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c728345",
   "metadata": {},
   "source": [
    "##### 예\n",
    "- 장치 두 개\n",
    "- 샘플들이 각 두 개 장치에 의해 처리됩니다\n",
    "- 손실값을 산출합니다. 각각의 장치에 대해 [2, 3]과 [4, 5]\n",
    "- Global batch size = 4  \n",
    "  \n",
    "    \n",
    "    \n",
    "- 샘플당 손실값을 계산\n",
    "  - (2 + 3) / 4 = 1.25\n",
    "  - (4 + 5) / 4 = 2.25  \n",
    "    \n",
    "  - tf.metrics.Mean : result()가 메서드 호출\n",
    "    - total : (2 + 3 + 4 + 5) / 4 = 3.5\n",
    "    - count : 2\n",
    "    - total / count = 1.75  \n",
    "      \n",
    "        \n",
    "- 두 개 같은 값인 것 같은데, 왜 추천하지 않는지 아직 이해하지 못하고 있습니다\n",
    "  - [1, 2, 3]과 [8, 10] 이런 경우는 달라질 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0044a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
